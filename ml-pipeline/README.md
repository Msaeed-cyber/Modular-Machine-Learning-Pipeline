# Modular ML Pipeline (Preprocessing â†’ Training â†’ Evaluation)

A clean, reusable template for supervised **classification** using scikit-learn. It separates the workflow into modules and saves all artifacts for reuse.

## ğŸ“ Project Structure
```text
ml-pipeline/
â”œâ”€ data/
â”‚  â””â”€ dataset.csv                 # put your CSV/Excel here
â”œâ”€ artifacts/                     # saved preprocessor, splits, models, metrics
â”œâ”€ plots/                         # confusion matrix, ROC/PR curves, feature importance
â”œâ”€ logs/
â”œâ”€ src/
â”‚  â”œâ”€ preprocessing.py            # loading, cleaning, encoding, scaling, splitting
â”‚  â”œâ”€ train_model.py              # model training + GridSearchCV
â”‚  â”œâ”€ evaluate.py                 # metrics + plots
â”‚  â””â”€ utils.py                    # logging + IO helpers
â”œâ”€ config.yaml                    # configure dataset & hyperparameter grids
â”œâ”€ main.py                        # orchestrates the full pipeline
â”œâ”€ requirements.txt
â””â”€ README.md
```

## ğŸ”§ Setup
```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate

pip install -r requirements.txt
```

## ğŸ“¦ Add Your Dataset
- Place your file at `data/dataset.csv` (or use Excel).
- Update `config.yaml`:
  - `target_col`: the name of your label column.
  - `dataset_path`: path to your file.
  - `excel_sheet`: sheet name for Excel (or set to null for CSV).
  - Optionally list `id_columns` to drop.

#### Example datasets (open-source)
- UCI Machine Learning Repository â€“ Heart Disease, Bank Marketing, etc.
  - https://archive.ics.uci.edu/
- OpenML â€“ many tabular datasets (CSV-friendly)
  - https://www.openml.org/

## â–¶ï¸ Run the Pipeline
```bash
# Run everything (preprocess â†’ train â†’ evaluate)
python main.py --config config.yaml --step all

# Or run step-by-step
python main.py --step preprocess
python main.py --step train
python main.py --step evaluate
```

## ğŸ§ª Models & Tuning
Configured in `config.yaml`:
- Logistic Regression, Decision Tree, Random Forest
- GridSearchCV over the provided parameter grids (scoring=`f1_macro` by default).

## ğŸ“Š Outputs
- `artifacts/preprocessor.joblib` â€“ fitted ColumnTransformer
- `artifacts/train_data.joblib` and `artifacts/test_data.joblib`
- `artifacts/best_model.joblib` â€“ best estimator
- `artifacts/train_meta.json` â€“ best model summary
- `artifacts/cv_results.csv` â€“ all CV rows
- `artifacts/evaluation_metrics.json` â€“ Accuracy, Precision, Recall, F1 (macro)
- `artifacts/classification_report.json` â€“ per-class metrics
- `plots/*.png` â€“ confusion matrix, ROC/PR curves, feature importance

## â™»ï¸ Reusability
- You can swap datasets by updating `config.yaml`.
- You can add more models by extending `models:` with a `type` and `param_grid`.

## ğŸ›¡ Best Practices
- Logging to `logs/pipeline.log`
- Reproducibility via `random_state` in `config.yaml`
- Meaningful exceptions on missing files/columns

## ğŸ“š References
- scikit-learn: Pipeline, ColumnTransformer, model selection, and metrics
  - Pipeline & ColumnTransformer: https://scikit-learn.org/stable/modules/compose.html
  - Imputation: https://scikit-learn.org/stable/modules/impute.html
  - OneHotEncoder: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html
  - GridSearchCV: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html
  - Classification metrics: https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics
  - Permutation importance: https://scikit-learn.org/stable/modules/permutation_importance.html
